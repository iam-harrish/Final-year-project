{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db347f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748/1748 [05:36<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748/1748 [05:24<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748/1748 [05:19<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748/1748 [05:16<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748/1748 [05:22<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed\n",
      "\n",
      "Hybrid model saved as hybrid_spoof_model.pth\n",
      "\n",
      "===== Evaluation =====\n",
      "Accuracy: 0.9152259332023576\n",
      "Precision: 0.9986676535899334\n",
      "Recall: 0.8876315789473684\n",
      "F1 Score: 0.939881574364333\n",
      "Confusion Matrix:\n",
      " [[2571    9]\n",
      " [ 854 6746]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================\n",
    "# PATH CONFIGURATION\n",
    "# ==========================\n",
    "BASE_PATH = \"/home/alaine/Downloads/LA\"\n",
    "AUDIO_PATH = os.path.join(BASE_PATH, \"ASVspoof2019_LA_train/flac\")\n",
    "PROTOCOL = os.path.join(BASE_PATH, \"ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\")\n",
    "\n",
    "TRAIN_ATTACKS = [\"A01\", \"A02\", \"A03\"]\n",
    "TEST_ATTACKS = [\"A04\", \"A05\"]\n",
    "\n",
    "# ==========================\n",
    "# PREPROCESSING\n",
    "# ==========================\n",
    "def preprocess_audio(path):\n",
    "    y, sr = librosa.load(path, sr=16000)\n",
    "\n",
    "    max_len = 4 * 16000\n",
    "    if len(y) > max_len:\n",
    "        y = y[:max_len]\n",
    "    else:\n",
    "        y = np.pad(y, (0, max_len - len(y)))\n",
    "\n",
    "    y = librosa.util.normalize(y)\n",
    "    return y, sr\n",
    "\n",
    "def extract_spectral(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "\n",
    "    mel_db = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-6)\n",
    "\n",
    "    mel_db = mel_db[:, :128]\n",
    "    if mel_db.shape[1] < 128:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0,128-mel_db.shape[1])))\n",
    "\n",
    "    mel_db = torch.tensor(mel_db).unsqueeze(0)\n",
    "    return mel_db.float()\n",
    "\n",
    "def extract_temporal(y):\n",
    "    frames = librosa.util.frame(y, frame_length=400, hop_length=160)\n",
    "    frames = frames.T\n",
    "    return torch.tensor(frames).float()\n",
    "\n",
    "# ==========================\n",
    "# DATASET\n",
    "# ==========================\n",
    "class ASVDataset(Dataset):\n",
    "    def __init__(self, audio_path, protocol_file, mode=\"train\"):\n",
    "        self.samples = []\n",
    "\n",
    "        rows = []\n",
    "        with open(protocol_file) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                file_id = parts[1]\n",
    "                attack = parts[3]\n",
    "                label = parts[4]\n",
    "                rows.append([file_id, attack, label])\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=[\"file\",\"attack\",\"label\"])\n",
    "\n",
    "        if mode == \"train\":\n",
    "            df = df[(df[\"attack\"].isin(TRAIN_ATTACKS)) | (df[\"label\"]==\"bonafide\")]\n",
    "        else:\n",
    "            df = df[(df[\"attack\"].isin(TEST_ATTACKS)) | (df[\"label\"]==\"bonafide\")]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            label = 0 if row[\"label\"]==\"bonafide\" else 1\n",
    "            self.samples.append((row[\"file\"], label))\n",
    "\n",
    "        self.audio_path = audio_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_id, label = self.samples[idx]\n",
    "        path = os.path.join(self.audio_path, file_id + \".flac\")\n",
    "\n",
    "        y, sr = preprocess_audio(path)\n",
    "        spectral = extract_spectral(y, sr)\n",
    "        temporal = extract_temporal(y)\n",
    "\n",
    "        return spectral, temporal, torch.tensor(label).float()\n",
    "\n",
    "# ==========================\n",
    "# MODELS\n",
    "# ==========================\n",
    "class SpectralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(32*32*32,64)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class TemporalGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=400, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128,64)\n",
    "\n",
    "    def forward(self,x):\n",
    "        _, h = self.gru(x)\n",
    "        x = self.fc(h[-1])\n",
    "        return x\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.spectral = SpectralCNN()\n",
    "        self.temporal = TemporalGRU()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, spec, temp):\n",
    "        f1 = self.spectral(spec)\n",
    "        f2 = self.temporal(temp)\n",
    "        fused = torch.cat((f1,f2), dim=1)\n",
    "        out = self.classifier(fused)\n",
    "        return out.squeeze()\n",
    "\n",
    "# ==========================\n",
    "# EVALUATION\n",
    "# ==========================\n",
    "def evaluate(model,loader,device):\n",
    "    model.eval()\n",
    "    preds, labels = [],[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for spec,temp,label in loader:\n",
    "            spec,temp = spec.to(device),temp.to(device)\n",
    "            output = torch.sigmoid(model(spec,temp))\n",
    "            pred = (output>0.5).cpu().numpy()\n",
    "\n",
    "            preds.extend(pred)\n",
    "            labels.extend(label.numpy())\n",
    "\n",
    "    print(\"\\n===== Evaluation =====\")\n",
    "    print(\"Accuracy:\", accuracy_score(labels,preds))\n",
    "    print(\"Precision:\", precision_score(labels,preds))\n",
    "    print(\"Recall:\", recall_score(labels,preds))\n",
    "    print(\"F1 Score:\", f1_score(labels,preds))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(labels,preds))\n",
    "\n",
    "# ==========================\n",
    "# TRAINING\n",
    "# ==========================\n",
    "def train_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    train_data = ASVDataset(AUDIO_PATH, PROTOCOL, mode=\"train\")\n",
    "    test_data  = ASVDataset(AUDIO_PATH, PROTOCOL, mode=\"test\")\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=0)\n",
    "    test_loader  = DataLoader(test_data, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = FusionModel().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for spec,temp,label in tqdm(train_loader):\n",
    "            spec,temp,label = spec.to(device),temp.to(device),label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(spec,temp)\n",
    "            loss = criterion(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Epoch\",epoch+1,\"completed\")\n",
    "\n",
    "    # Save unified hybrid model\n",
    "    torch.save(model.state_dict(), \"hybrid_spoof_model.pth\")\n",
    "    print(\"\\nHybrid model saved as hybrid_spoof_model.pth\")\n",
    "\n",
    "    evaluate(model,test_loader,device)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c08556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- RESULT -----\n",
      "Prediction: AI (spoof)\n",
      "Confidence: 0.9948\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import nn\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "# =========================\n",
    "# CHANGE THIS\n",
    "# =========================\n",
    "INPUT_PATH = \"/home/alaine/Downloads/LA/ASVspoof2019_LA_dev/flac/LA_D_1023711.flac\"\n",
    "MODEL_PATH = \"hybrid_spoof_model.pth\"\n",
    "\n",
    "# =========================\n",
    "# PREPROCESSING\n",
    "# =========================\n",
    "def preprocess_audio(path):\n",
    "    y, sr = librosa.load(path, sr=16000)\n",
    "\n",
    "    max_len = 4 * 16000\n",
    "    if len(y) > max_len:\n",
    "        y = y[:max_len]\n",
    "    else:\n",
    "        y = np.pad(y, (0, max_len - len(y)))\n",
    "\n",
    "    y = librosa.util.normalize(y)\n",
    "    return y, sr\n",
    "\n",
    "def extract_spectral(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "\n",
    "    mel_db = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-6)\n",
    "\n",
    "    mel_db = mel_db[:, :128]\n",
    "    if mel_db.shape[1] < 128:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0,128-mel_db.shape[1])))\n",
    "\n",
    "    mel_db = torch.tensor(mel_db).unsqueeze(0)\n",
    "    return mel_db.float()\n",
    "\n",
    "def extract_temporal(y):\n",
    "    frames = librosa.util.frame(y, frame_length=400, hop_length=160)\n",
    "    frames = frames.T\n",
    "    return torch.tensor(frames).float()\n",
    "\n",
    "# =========================\n",
    "# MODEL DEFINITIONS\n",
    "# =========================\n",
    "class SpectralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(32*32*32,64)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class TemporalGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=400, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128,64)\n",
    "\n",
    "    def forward(self,x):\n",
    "        _, h = self.gru(x)\n",
    "        x = self.fc(h[-1])\n",
    "        return x\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.spectral = SpectralCNN()\n",
    "        self.temporal = TemporalGRU()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, spec, temp):\n",
    "        f1 = self.spectral(spec)\n",
    "        f2 = self.temporal(temp)\n",
    "        fused = torch.cat((f1,f2), dim=1)\n",
    "        out = self.classifier(fused)\n",
    "        return out.squeeze()\n",
    "\n",
    "# =========================\n",
    "# VIDEO HANDLING\n",
    "# =========================\n",
    "def extract_audio_from_video(video_path):\n",
    "    temp_audio = \"temp_audio.wav\"\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.audio.write_audiofile(temp_audio, fps=16000, logger=None)\n",
    "    clip.close()\n",
    "    return temp_audio\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FusionModel().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# HANDLE INPUT\n",
    "# =========================\n",
    "video_extensions = (\".mp4\", \".mkv\", \".avi\", \".mov\")\n",
    "\n",
    "if INPUT_PATH.lower().endswith(video_extensions):\n",
    "    print(\"Video detected. Extracting audio...\")\n",
    "    audio_path = extract_audio_from_video(INPUT_PATH)\n",
    "else:\n",
    "    audio_path = INPUT_PATH\n",
    "\n",
    "# =========================\n",
    "# PREDICTION\n",
    "# =========================\n",
    "y, sr = preprocess_audio(audio_path)\n",
    "\n",
    "spectral = extract_spectral(y, sr).unsqueeze(0).to(device)\n",
    "temporal = extract_temporal(y).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(spectral, temporal)\n",
    "    probability = torch.sigmoid(output).item()\n",
    "\n",
    "print(\"\\n----- RESULT -----\")\n",
    "\n",
    "if probability > 0.5:\n",
    "    print(\"Prediction: AI (spoof)\")\n",
    "else:\n",
    "    print(\"Prediction: REAL (bonafide)\")\n",
    "\n",
    "print(f\"Confidence: {probability:.4f}\")\n",
    "\n",
    "if audio_path == \"temp_audio.wav\" and os.path.exists(audio_path):\n",
    "    os.remove(audio_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
