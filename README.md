<div align="center">

<img src="deepguard_logo_1771843398894.png" alt="DeepGuard AI Logo" width="180"/>

# ğŸ™ï¸ DeepGuard AI â€” Deepfake Audio Detection System

**Detect AI-generated and spoofed voices with state-of-the-art Hybrid CNN+GRU deep learning.**

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org)
[![Flask](https://img.shields.io/badge/Flask-3.1-000000?logo=flask&logoColor=white)](https://flask.palletsprojects.com)
[![React](https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=black)](https://reactjs.org)
[![Librosa](https://img.shields.io/badge/Librosa-0.10-green)](https://librosa.org)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

</div>

---

## ğŸ“Œ Overview

**DeepGuard AI** is a full-stack web application that detects **AI-generated (deepfake) speech** using a **Hybrid CNN + GRU Fusion Model** trained on the **ASVspoof 2019 LA dataset**. Upload an audio or video file, and the system will tell you within seconds whether the voice is **REAL** or **AI-generated** â€” with a confidence score.

> **Model Accuracy: 91.52% | Precision: 99.87% | F1 Score: 93.99%**

---

## âœ¨ Features

- ğŸ”Š **Audio & Video Support** â€” Upload `.wav`, `.flac`, `.mp3`, `.ogg`, `.m4a`, `.mp4`, `.mkv`, `.avi`, and more
- ğŸ§  **Hybrid Dual-Branch Model** â€” SpectralCNN (mel-spectrogram) + TemporalGRU (raw audio frames) fusion
- ğŸ“Š **Confidence Scores** â€” Real vs. Fake probability with confidence percentage
- ğŸ“ˆ **Model Performance Dashboard** â€” Live accuracy, precision, recall, F1 score, ROC curve, confusion matrix, and training loss charts
- ğŸ” **User Authentication** â€” JWT-based login/registration system
- ğŸ“œ **Prediction History** â€” Browse all past detections with timestamps
- ğŸ—ï¸ **How It Works** â€” Step-by-step explanation of the detection pipeline
- ğŸŒ‘ **Premium Dark UI** â€” Glassmorphism design, smooth animations, responsive layout

---

## ğŸ§  Model Architecture

The detection model is a **Hybrid Fusion Model** that processes audio through two parallel branches and combines their outputs for a comprehensive deepfake decision.

```
Input Audio (16kHz, 4s)
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Preprocessing              â”‚
â”‚  â€¢ Pad/trim to 4 seconds           â”‚
â”‚  â€¢ Amplitude normalization         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
    â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mel-       â”‚      â”‚ Raw Audio    â”‚
â”‚ Spectrogramâ”‚      â”‚ Framing      â”‚
â”‚ (128Ã—128)  â”‚      â”‚ (400-sample  â”‚
â”‚            â”‚      â”‚  windows)    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚
      â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SpectralCNNâ”‚      â”‚ TemporalGRU  â”‚
â”‚ Conv2d     â”‚      â”‚ GRU(400â†’128) â”‚
â”‚ 1â†’16â†’32    â”‚      â”‚ + FC(128â†’64) â”‚
â”‚ + FCâ†’64    â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Concat (128-dim)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Classifier      â”‚
        â”‚ Linear(128â†’64)  â”‚
        â”‚ ReLU            â”‚
        â”‚ Linear(64â†’1)    â”‚
        â”‚ Sigmoid         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚
       FAKE            REAL
   (prob > 0.5)    (prob â‰¤ 0.5)
```

### Model Performance (ASVspoof 2019 LA â€” Test Set)

| Metric    | Score     |
|-----------|-----------|
| Accuracy  | **91.52%** |
| Precision | **99.87%** |
| Recall    | **88.76%** |
| F1 Score  | **93.99%** |

**Confusion Matrix (10,180 samples):**
|                 | Predicted REAL | Predicted FAKE |
|-----------------|:--------------:|:--------------:|
| **Actual REAL** |   2571 âœ…       |   9 âŒ          |
| **Actual FAKE** |   854 âŒ        |   6746 âœ…       |

---

## ğŸ› ï¸ Technology Stack

### Backend
| Technology | Version | Purpose |
|---|---|---|
| Python | 3.10+ | Core language |
| Flask | 3.1 | REST API server |
| Flask-JWT-Extended | 4.7 | Authentication |
| PyTorch | 2.x | Deep learning framework |
| Librosa | 0.10.2 | Audio feature extraction |
| MoviePy | 2.1.2 | Video audio extraction |
| SQLite | Built-in | User & prediction database |
| NumPy | Latest | Numerical operations |
| scikit-learn | 1.6.1 | Metrics calculation |

### Frontend
| Technology | Version | Purpose |
|---|---|---|
| React | 18 | UI framework |
| Vite | 5 | Build tool |
| Recharts | Latest | Performance charts |
| Axios | Latest | HTTP client |
| CSS3 Glassmorphism | â€” | Premium dark theme |

---

## ğŸ“ Project Structure

```
AI audio detection/
â”‚
â”œâ”€â”€ ğŸ““ detection.ipynb              # Hybrid model training notebook
â”œâ”€â”€ ğŸ¤– hybrid_spoof_model.pth       # Trained hybrid model weights
â”œâ”€â”€ ğŸ“– README.md                    # This file
â”œâ”€â”€ ğŸ–¼ï¸ deepguard_logo_1771843398894.png  # Project logo
â”‚
â”œâ”€â”€ backend/                        # Flask API server
â”‚   â”œâ”€â”€ app.py                      # Main Flask app & API endpoints
â”‚   â”œâ”€â”€ model.py                    # Hybrid FusionModel + feature extraction
â”‚   â”œâ”€â”€ generate_metrics.py         # Metrics generation script
â”‚   â”œâ”€â”€ metrics.json                # Cached model metrics
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ uploads/                    # Temporary upload storage
â”‚
â””â”€â”€ frontend/                       # React web application
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.jsx                 # Main app with routing
    â”‚   â”œâ”€â”€ services/api.js         # Axios API service layer
    â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx       # Main dashboard page
    â”‚   â”‚   â””â”€â”€ Login.jsx           # Auth page (login/register)
    â”‚   â””â”€â”€ components/
    â”‚       â”œâ”€â”€ AudioUpload.jsx     # Drag & drop file uploader
    â”‚       â”œâ”€â”€ DetectionResult.jsx # Prediction result display
    â”‚       â”œâ”€â”€ History.jsx         # Prediction history table
    â”‚       â”œâ”€â”€ HowItWorks.jsx      # Pipeline explanation
    â”‚       â””â”€â”€ ModelAccuracy.jsx   # Performance charts
    â””â”€â”€ package.json
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+ (with pip)
- Node.js 18+ (with npm)
- The trained model file: `hybrid_spoof_model.pth` (included in the root folder)

---

### Backend Setup

**1. Navigate to the backend directory:**
```bash
cd "AI audio detection/backend"
```

**2. Create and activate a virtual environment:**
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS / Linux
python -m venv .venv
source .venv/bin/activate
```

**3. Install dependencies:**
```bash
pip install -r requirements.txt
```

**4. Start the Flask server:**
```bash
python app.py
```

The backend will start at **`http://localhost:5000`**.

> **First launch:** The server automatically initializes the SQLite database and generates `metrics.json`.

---

### Frontend Setup

**1. Navigate to the frontend directory:**
```bash
cd "AI audio detection/frontend"
```

**2. Install Node dependencies:**
```bash
npm install
```

**3. Start the development server:**
```bash
npm run dev
```

The frontend will be available at **`http://localhost:5173`**.

---

## ğŸ”Œ API Reference

All endpoints are prefixed with `/api/`.

### Authentication

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|:---:|
| `POST` | `/api/auth/register` | Register a new user | âŒ |
| `POST` | `/api/auth/login` | Login and receive JWT token | âŒ |
| `GET` | `/api/auth/me` | Get current user info | âœ… |

**Register / Login Request Body:**
```json
{
  "username": "yourname",
  "email": "you@email.com",
  "password": "yourpassword"
}
```

---

### Prediction

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|:---:|
| `POST` | `/api/predict` | Run deepfake detection on uploaded file | âœ… |

**Request:** `multipart/form-data` with field `file`

**Response:**
```json
{
  "filename": "audio_sample.wav",
  "label": "FAKE",
  "confidence": 94.88,
  "real_probability": 5.12,
  "fake_probability": 94.88,
  "raw_score": 0.948832
}
```

---

### History & Metrics

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|:---:|
| `GET` | `/api/history` | Get user's prediction history (last 50) | âœ… |
| `GET` | `/api/metrics` | Get model performance metrics | âŒ |
| `GET` | `/api/how-it-works` | Get pipeline explanation content | âŒ |
| `GET` | `/api/health` | Server health check | âŒ |

---

## ğŸ›ï¸ How It Works

### Step 1 â€” Upload
Upload any supported audio or video file. For videos, the audio track is automatically extracted.

### Step 2 â€” Dual Feature Extraction
The audio is preprocessed to **4 seconds at 16 kHz** (padded/trimmed and normalized), then processed through **two parallel feature pipelines**:
- **Mel Spectrogram** (128Ã—128) â€” captures frequency-domain patterns over time
- **Temporal Frames** â€” raw audio framed into 400-sample windows (hop=160) for sequence analysis

### Step 3 â€” Hybrid Neural Network
- **SpectralCNN** branch: Two Conv2D layers (1â†’16â†’32 channels) with MaxPooling extract spatial features from the mel spectrogram â†’ 64-dim output
- **TemporalGRU** branch: A GRU with 128 hidden units processes the sequential audio frames â†’ 64-dim output
- Both 64-dim vectors are **concatenated** â†’ 128-dim fused feature
- A **classifier head** (`Linear(128â†’64) â†’ ReLU â†’ Linear(64â†’1)`) produces the final logit

### Step 4 â€” Prediction
Sigmoid activation converts the logit to a probability:
- **> 0.5** â†’ ğŸ”´ **FAKE** (AI-generated / spoofed)
- **â‰¤ 0.5** â†’ ğŸŸ¢ **REAL** (bonafide)

---

## ğŸ‹ï¸ Training

The model was trained using the **ASVspoof 2019 Logical Access (LA)** dataset:

- **Training attacks:** A01, A02, A03 (+ all bonafide samples)
- **Test attacks:** A04, A05 (+ all bonafide samples)
- **Optimizer:** Adam (lr=1e-4)
- **Loss function:** BCEWithLogitsLoss
- **Epochs:** 5
- **Batch size:** 8

To retrain the model, open `detection.ipynb` and update `BASE_PATH` to your dataset location, then run all cells.

---

## ğŸ“Š Supported File Formats

| Type | Formats |
|------|---------|
| ğŸµ Audio | `.wav` `.flac` `.mp3` `.ogg` `.m4a` `.aac` `.wma` |
| ğŸ¬ Video | `.mp4` `.mkv` `.avi` `.mov` `.webm` `.wmv` `.flv` |

**Maximum file size:** 50 MB

---

## ğŸ”’ Security

- JWT tokens expire after **24 hours**
- Passwords are hashed using **SHA-256**
- All uploaded files are **automatically deleted** after processing
- CORS is restricted to API routes only

---

## ğŸ“ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

- [ASVspoof 2019 Challenge](https://www.asvspoof.org/) â€” Training dataset
- [Librosa](https://librosa.org/) â€” Audio processing library
- [PyTorch](https://pytorch.org/) â€” Deep learning framework

---

<div align="center">
  <p>Built with â¤ï¸ using PyTorch, Flask, and React</p>
  <img src="deepguard_logo_1771843398894.png" alt="DeepGuard AI" width="60"/>
</div>
#   F i n a l - y e a r - p r o j e c t  
 